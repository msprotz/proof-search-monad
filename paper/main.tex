\documentclass{easychair}

\usepackage{fontspec}
  \defaultfontfeatures{Mapping=tex-text}
\usepackage{ucharclasses}
  \setTransitionsFor{MathematicalOperators}{\begingroup\fontspec{DejaVu Sans}[Scale=MatchLowercase]}{\endgroup}
\usepackage{xunicode}

\usepackage{xltxtra}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{amstext}
\usepackage{amsthm}
\usepackage{hyperref}

\usepackage{enumerate}
\usepackage{tabularx}
\usepackage{listings}
  \def\li{\lstinline}
  \lstset{
    language=caml,
    flexiblecolumns=false,
    showstringspaces=false,
    basicstyle=\ttfamily,
    framesep=5pt,
    numberstyle=\tiny,
    numbersep=5pt,
    escapeinside={(*}{*)},
    deletekeywords={value},
  }
\usepackage{minted}
  \newminted[ocaml]{ocaml}{mathescape,fontsize=\small}
\usepackage{mathpartir}
  % Improvements to Didier's mathpartir package: make all rule names and
  % references use textsc, and also make references to rules done using the \Rule
  % command clickable in a PDF.
  \let\TirName\textsc
  % \renewcommand{\RefTirName}[1]{\hypertarget{#1}{\TirName {#1}}}
  \renewcommand{\DefTirName}[1]{\hyperlink{#1}{\TirName {#1}}}
  % \let\DefRule\RefTirName
  \let\Rule\DefTirName
  % \let\Rule\textsc


\newcommand{\fref}[1]{Figure~\ref{fig:#1}}
\newcommand{\sref}[1]{Section~\ref{sec:#1}}
\newcommand{\R}{\ensuremath{\mathcal{R}}} % Rigid
\newcommand{\f}[1]{\ensuremath{#1^?}} % Bold
\newcommand{\F}{\ensuremath{\mathcal{F}}} % Flexible
\newcommand{\V}{\ensuremath{\mathcal{V}}} % The prefix

\begin{document}

\title{Functional Pearl: the Proof Search Monad}
\titlerunning{The Proof Search Monad}

\author{Jonathan Protzenko}
\authorrunning{J. Protzenko}
\institute{
  Microsoft Research\\
  \email{protz@microsoft.com}}

\maketitle

\begin{abstract}
  We present the proof search monad, a set of combinators that allows one to
  write a proof search engine in a style that resembles the formal rules
  closely. The user calls functions such as \li+premise+, \li+prove+ or
  \li+choice+; the library then takes care of generating a derivation tree.
  Proof search engines written in this style enjoy: first, a one-to-one
  correspondence between the implementation and the derivation rules, which
  makes manual inspection easier; second, proof witnesses ``for free'', which
  makes a verified, independent validation approach easier too.
\end{abstract}

\section{Theory and practice}
\label{sec:intro}

This paper attempts to present, in a tutorial-style, the design of an OCaml
library. In order to facilitate the discussion, we focus on a very constrained
logic; later (\sref{extending}), we mention how to extend the library to
cover more use-cases. The original motivation for the library was to serve as a
core building block for the type-checker of Mezzo~\cite{protzenko-phd-14}. The
nature of the core, minimal logic that we are about to present is, of course,
inspired by typical nature of type-checking problems: it features equality,
quantifiers, and positive literals; \sref{extending} mentions how to extend it
with function symbols and variance (negative positions), as is typical for
type-checking problems.

\subsection{A minimal theory}

We are concerned with proving the validity of logical formulas; that is, with
writing a search procedure that determines whether a given goal is satisfiable.
To get started, we consider a system made up of conjunctions of equalities,
along with existential quantifiers. Any free variables are assumed to be
universally quantified. For instance, one may want to prove the following
formula:

\begin{equation}
  \exists y.\ x = y
  \label{ex1}
\end{equation}

In order to show the validity of this judgement, one usually builds a proof
derivation using rules from the logic. In our case, the rules are given in
\fref{logic}, where $[x/y]P$ means ``substitute $x$ with $y$ in $P$''. For
instance, proving Equation \ref{ex1} requires applying \Rule{ExistsE}, then
\Rule{Refl}.

\begin{figure}
  \centering
  \begin{mathpar}
    \inferrule[Refl]{
      \quad
    }{
      x = x
    }

    \inferrule[And]{
      P \\ Q
    }{
      P \wedge Q
    }

    \inferrule[ExistsE]{
      [x/y]P
    }{
      \exists y.\ P
    }
  \end{mathpar}
  \caption{A simple logic}
  \label{fig:logic}
\end{figure}

These rules embody the Truth of our logic, i.e. an omniscient reader may use
them to show with absolute certainty that a given formula is true.
%
However, if one wants to algorithmically determine whether a given formula is
true, \Rule{ExistsE} is useless. Indeed, unless the algorithm (solver) is
equipped with superpowers, it cannot magically guess, out of the blue, a
suitable $x$ in \Rule{ExistsE} that will ensure the remainder of the derivation
succeeds. To put it another way, $x$ is a free variable (a parameter) of
\Rule{ExistsE}; the whole point of writing a proof search algorithm is to 1)
find that \Rule{ExistsE} is the right rule to apply, and 2) find that $x$ is a
suitable value for instantiating $y$, because it will make $y = x$ succeed.

Hence, in order to build a \emph{search procedure} for that logic, one will
use another set of \emph{algorithmic} rules, which hopefully enjoy:
\begin{description}
  \item[soundness]: if the algorithmic rules succeed, then there exists a
    derivation in the logic that proves the validity of the original formula,
    and
  \item[completeness]: if the algorithmic rules fail, then there exists no
    derivation in the logic that would prove the validity of the original
    formula.
\end{description}

For instance, in our logic of existentially-quantified conjunctions of
equalities, one may want to use the rules from \fref{proof-system}. These rules
differ from \fref{logic} in that they are algorithmic; they take an input and
return an output.

\begin{figure}
  \centering
  \begin{mathpar}
    \inferrule[Refl]{
      \quad
    }{
      V, \sigma \vdash x = x \dashv \sigma
    }

    \inferrule[Subst]{
      V, \sigma \vdash \sigma P \dashv \sigma'
    }{
      V, \sigma \vdash P \dashv \sigma'
    }

    \inferrule[Inst]{
      x \in V \\ \f y \in V \\ \f y \not\in \sigma \\\\
      V, \{ \f y \mapsto x \} \circ \sigma \vdash  P \dashv \sigma'
    }{
      V \vdash P \dashv \sigma'
    }

    \inferrule[And]{
      V, \sigma \vdash P \dashv \sigma' \\\\
      V, \sigma' \vdash Q \dashv \sigma''
    }{
      V \vdash P \wedge Q \dashv \sigma''
    }

    \inferrule[ExistsE]{
      V \uplus \f y, \sigma \vdash P \dashv \sigma'
    }{
      V, \sigma \vdash \exists y.\ P \dashv \sigma'_{|V}
    }
  \end{mathpar}
  \caption{Algorithmic proof rules}
  \label{fig:proof-system}
\end{figure}

In particular, in order to determine suitable values for the $x$ parameter in
\Rule{ExistsE}, the implementation reasons in terms of substitutions. $V$ is a
set of variables which may be substituted (recall that free variables are
considered universally quantified, hence not eligible for substitution);
variables that may be substituted are typeset as $\f y$.
The algorithm has internal state, that is, it carries a substitution $\sigma$.
Upon hitting an existential quantifier $\f y$, the algorithmic rules
\emph{open} $\f y$ and mark it as eligible for substitution (\Rule{ExistsE}).
Later on (for instance, upon hitting $\f y = x$), the algorithm may pick a
substitution for $\f y$ using \Rule{Inst}. A substitution may be applied at any
time (\Rule{Subst}). The preconditions of \Rule{Inst} guarantee that the
algorithm makes at most one choice for instantiating $\f y$.

In other words, the algorithmic rules \emph{defer} the \emph{instantiation} of
the existential quantifier until some sub-goal, later on, gives us a \emph{hint}
as to what exactly this instantiation should be. This \emph{implementation
technique} is known as \emph{flexible variables}.

The new algorithmic rules differ from the original logical rules significantly;
first, there are five rules for the algorithmic system, compared to just three
for the logical system. Second, these five rules do not map trivially to their
counterparts in the logical system. Third, these rules are still very much
abstract; the implementation that we are about to roll out uses an
optimized representation for substitutions (union-find) that is not formalized
in \fref{proof-system}. Phrased differently, one not only needs to check that
the algorithmic rules are faithful to the proof rules, but also that the
implementation itself is faithful to the algorithmic rules.

This paper presents a library that allows one to write an implementation of the
algorithmic rules while automatically generating a derivation. The library
forces the client code to lay out premises, rule applications and
instantiations. The level of detail of the resulting derivation is left up to
the client code; the user may wish to record a proof derivation using the proof
rules, or record a trace of the algorithm using the algorithmic rules.  In any
case, the derivation serves as a witness; in the case of a proof derivation, a
validator may certify that the proof is valid, while in the case of an
algorithmic trace, the user may verify the algorithm, or inspect the trace for
debugging or feedback purposes.

The library has been used, in a preliminary form, to implement the core of the
Mezzo type-checker~\cite{protzenko-phd-14}. This paper presents a cleaned-up,
isolated version of this library that exposes a proper interface using monads
and domain-specific combinators.

\subsection{An implementation with flexible variables and union-find}

The logic we present is a much simplified version of the logic (type system) of
Mezzo~\cite{pottier-protzenko-13}. In the present document, we only mention the
right-exists quantifier. General systems such as Mezzo have all four possible
combinations of left/right exists/forall.
%
The right-elimination of existential quantifiers, or the left-elimination of
universal quantifiers gives \emph{flexible variables}, while the
right-elimination of universal quantifiers, or the left-elimination of
existential quantifiers gives universally-quantified variables, also called
\emph{rigid variables}.

In order to simplify the problem, we assume that all existential variables have
been introduced as flexible variables already. That way, we won't be
sidetracked, talking about binders and the respective merits of De Bruijn
\emph{vs.} locally nameless. Furthermore, we assume that all instantiations of
flexible variables are legal. This is not true in general: for instance, if the
goal is $\forall x, \exists \f y, \forall z.\ P$, picking $\f y = z$ makes no
sense. Mezzo forbids this choice using \emph{levels}~\cite{pottier-remy-emlti}; in the present document,
we skip this discussion altogether and assume that ``all is well''. Finally,
although in a general setting, several rules may trigger for a given goal (this
is the case in Mezzo), the algorithmic set of rules we use is syntax-driven: the
syntactic shape of the goal determines which rule should be applied.

We thus restrict our formulas to conjunctions of equalities between variables.
The plan is to write a solver that takes,
as an input, a formula, and outputs a valid substitution, if any. That is,
write an algorithm that abides by the rules from \fref{proof-system}.
For instance, one may want to solve: $x = \f y \wedge z = z$.
A solution exists: the solver outputs $\sigma = \{ \f y \mapsto x \}$ as a valid
substitution that solves the input problem. However, if one attempts to solve:
$x = \f y \wedge \f y = z$, the solver fails to find a
proper substitution, and returns nothing. Indeed, the first clause demands that
$\f y$ substitutes to $x$, meaning that the second clause becomes $x = z$, which
always evaluates to false ($x$ and $z$ are two distinct rigid variables).

Once the algorithm has run, we obtain an output substitution $\sigma$. One can, if they
wish to do so, take the reflexive-transitive closure $\sigma^*$, and apply it to
a flexible variable (say, $\f y$) to recover the parameter of \Rule{ExistsE}
that should be used in the logical rules (here, $x$). This way of checking
correctness is not satisfactory and does not scale if nested quantifiers appear
in the goal; the point of the subsequent sections is to make sure the search
algorithm produces a proper proof witness (derivation) that has a tree-like
structure and does not leak implementation details (such as substitutions).

\begin{figure}
  \centering
  \begin{ocaml}
type formula =                and descr =
| Equals of var * var           | Flexible
| And of formula * formula      | Rigid

and var = P.point             and state = descr P.state
  \end{ocaml}
  \caption{Formulas and state}
  \label{fig:formulas}
\end{figure}

We implement proof search in OCaml~\cite{ocaml} (\fref{formulas}); we implement substitutions
using a union-find data structure~\cite{cormen-en,tarjan-75}. The data type of formulas
is self-explanatory. Variables are implemented as equivalence classes in the
\emph{persistent} union-find data structure, which the module \li+P+ implements.
The $V, \sigma$ parameters in our rules are embodied by the \li+state+ type; just
like the $\sigma$ parameter is chained from one premise to another (\Rule{And}),
\li+state+ is an input and an output to the solver. Just like the $\sigma$ parameter
in the rules, a \li+state+ of the persistent union-find represents
a set of equations between variables. The algorithmic rules mentioned a
theoretical $\sigma$ parameter; the \li+state+ is our specific implementation
choice.

The choice of a union-find (as opposed to explicit substitutions) is irrelevant.
All that matters is that we pick a data structure that models substitutions, and
that the structure be \emph{persistent}.

\fref{solver} implements a solver for our minimal problem; since we perform
computations that either return a result of a failure, the code leads itself
well to an implementation using
monads~\cite{wadler-comprehending-92,wadler-essence-92}, in our case, the
\li+MOption+ monad. The \li+Some state+ is for success, meaning a substitution
has been found, while the \li+None+ case means no solution exists. The solver is
complete.

\begin{figure}
  \centering
  \begin{ocaml}
module MOption = struct
  (* ... defines [return], [nothing] and [>>=] *)
end

let unify state v1 v2: state =                  let rec solve state formula: state =
  match P.find v1 state, P.find v2 state with     match formula with
  | Flexible, Flexible                            | Equals (v1, v2) ->
  | Flexible, Rigid ->                                unify state v1 v2
      return (P.union v1 v2 state)                | And (f1, f2) ->
  | Rigid, Flexible ->                                solve state f1 >>= fun state ->
      return (P.union v2 v1 state)                    solve state f2
  | Rigid, Rigid ->
      if P.same v1 v2 state then
        return state
      else
        nothing
  \end{ocaml}
  \caption{Solver for the simplified problem}
  \label{fig:solver}
\end{figure}

The solver uses \li+MOption.>>=+ to sequence premises in the \li+And+ case. It
doesn't keep track of premises; it just ensures (thanks to \li+>>=+) that if the
first premise evaluates to \li+nothing+, the second premise is not evaluated,
since it is suspended behind a \li+fun+ expression (OCaml is a strict language).

\section{Building derivations}
\label{sec:derivations}

There are two shortcomings with this solver. First, the \li+unify+ sub-routine
conflates several rules together. Indeed, the \li+return (P.union ...)+
expression hides a combination of \Rule{Inst} and \Rule{Refl}. Second, we
have no way to replay the proof to verify it independently. One may argue that
in this simplified example, the outputs substitution \emph{is} the proof
witness: one can just apply the substitution to the original
formula and verify that all the clauses are of the form $x = x$, without the
need for a proof tree. In the general case, however, the proof tree contains the
\Rule{ExistsE} rule, and proof witnesses are attached to arbitrary nodes of the
tree. We thus need to build a properly annotated proof tree in the general case.

\subsection{Defining proof trees}

One way to make the solver better is to make sure each step it performs
corresponds in an obvious manner to the application of an admissible rule. To
that effect, we define the data type of all three rules in our system, which we
apply to the functor of \emph{proof trees} (\fref{proof-trees}).

We record applications of \Rule{Inst}, \Rule{Refl} and \Rule{And}. This produces
a derivation tree (algorithm trace) that makes sure that the algorithm follows
the algorithmic rules from \fref{proof-system}. \sref{generate-logical} shows
how to generate a different, more compact tree that matches the rules from
\fref{logic}.

\begin{figure}
  \centering
\begin{ocaml}
(* These two modules belong to the library. *)
module type LOGIC = sig     module Derivations.Make (L: LOGIC) = struct
  type formula                type derivation = L.formula * rule
  type rule_name              and rule = L.rule_name * premises
end                           and premises = Premises of derivation list
                            end

(* This is the client code using modules from the library. *)
module MyLogic = struct
  type formula = ... (* as before *)
  type rule_name = R_And | R_Refl | R_Inst
end
module MyDerivations = Derivations.Make(MyLogic)
\end{ocaml}
  \caption{The functor of proof trees (library and client code)}
  \label{fig:proof-trees}
\end{figure}

A \li+derivation+ tree is a pair of a \li+formula+ (the goal we wish the prove)
and a \li+rule+ (that we apply in order to prove the goal). A \li+rule+ has a name
and \li+premises+; the \li+premises+ type is simply a \li+derivation list+ (the
\li+Premises+ constructor is here to prevent a non-constructive type
abbreviation). When using the library, the client is expected to make sure
that each \li+rule_name+ is paired with the proper
number of premises (0 for \Rule{Refl}, 1 for
\Rule{Inst} and 2 for \Rule{And}); this is not enforced by the type system.

In the (simplified) sketch from \fref{proof-trees}, rule names are just constant
constructors, since the rule parameters (such as $x$ and $\f y$ in \Rule{Inst})
can be recovered from the \li+formula+. In the general case
(\sref{generate-logical}), the various constructors of \li+rule_name+ do have
parameters that record how one specific rule was instantiated.

\subsection{Proof tree combinators}

We previously used the \li+>>=+ operator from the \li+MOption+ monad in order to
chain premises (\fref{solver}). We now need a new operator, that not only
\emph{binds} the result (i.e. stops evaluating premises after a failure, as
before), but also \emph{records} the premises in sequence, in order to build a
proper derivation. The former is still faithfully implemented by the option
monad; the latter is implemented by the writer monad~\cite{jones-95-}.

Computations in the writer monad return a result (of type \li+'a+) along with a log of
elements (of type \li+L.a+). The (usual) \li+>>=+ and \li+return+ combinators operate on
the result part of the computation, while the (new) \li+tell+ combinator
operates on the logging part of the computation. The \li+tell+ combinator
appends a new element to the log; this is done by way of the \li+MONOID+ module
type, which essentially demands a value for the \li+empty+ log, and a function
to \li+append+ new entries into the log.

In order to get a new \li+>>=+ operator that combines the features of
the option and writer monads, we apply the \li+WriterT+ monad transformer to the
\li+MOption+ monad (\fref{writer}) and obtain \li+MWriter+.

\begin{figure}
  \centering
\begin{ocaml}
module WriterT (M: MONAD) (L: MONOID): sig      module L = struct
  type 'a m = (L.a * 'a) M.m                      type a = Derivations.derivation list
  val return: 'a -> 'a m                          let empty = []
  val ( >>= ): 'a m -> ('a -> 'b m) -> 'b m       let append = List.append
                                                end
  val tell: L.a -> unit m
end = ...

module M = MOption
module MWriter = WriterT(M)(L)
\end{ocaml}
  \caption{The writer monad transformer (library code)}
  \label{fig:writer}
\end{figure}

The type of computations \li+'a MWriter.t+ boils down (after functor
application) to \li+(derivation list * state) option+. A computation in the monad
represents a given point in the proof; the solver is focused on a rule; has
proved a number of premises so far (the \li+derivation list+); has reached a
certain \li+state+ (threaded through the premises). The \li+option+ type
accounts for failure; in case a premise cannot be proved, the computation aborts
and becomes \li+None+.

Once all the premises have been proven, one needs to draw a horizontal line and
reach the conclusion of the proof. That is, take the final state and the list of
premises, and generate a \li+derivation+ that stands for the application of the
entire rule.

Contrary to the first implementation (\fref{solver}), where the working state
and the return value of \li+solve+ both had type \li+state option+, we now
distinguish between an \li+outcome+ (the result of a call to \li+solve+) and a
working state (a computation in the \li+MWriter+ monad).

An \li+outcome+ is the pair of a final \li+state+ along
with a \li+derivation+ that justifies that we reached this state. The pair is
wrapped in \li+M.t+ (here, \li+option+): if the computation of premises is a
failure, then the proof of the desired goal is a failure too.

The type \li+outcome+ (\fref{combinators}) is parametric: it works for any
state that the client code uses. In other words, our library is generic with
regards to the particular \li+state+ type the client uses.

\begin{figure}
  \centering
\begin{ocaml}
(* This snippet is in the [MWriter(M)(L)] monad. Upon a first reading, think
   [module M = MOption]. *)
type 'a outcome = ('a * derivation) M.m

let premise (outcome: 'a outcome): 'a m =
  M.bind outcome (fun (state, derivation) ->
    tell [ derivation ] >>= fun () ->
    return state
  )

let prove (goal: goal) (x: ('a * rule_name) m): 'a outcome =
  M.(x >>= fun (premises, (state, rule)) ->
    return (state, (goal, (rule, Premises premises))))

let axiom (state: 'a) (goal: goal) (axiom: rule_name): 'a outcome =
  prove goal (return (state, axiom))

let qed r e =
  return (e, r)

let fail: 'a outcome =
  M.nothing
\end{ocaml}
  \caption{The high-level combinators for building proof derivations (library
  code)}
  \label{fig:combinators}
\end{figure}

We now have a duality between the \li+outcome+ type (the result of solving a
goal) and the \li+m+ type (a computation within the monad, i.e. a working
state between two premises). Therefore, we introduce two high-level combinators:
\li+premise+ and \li+prove+. The former goes from \li+outcome+ to \li+m+: it
injects a new sub-goal as a premise of the rule we are currently trying to
prove. The latter goes from \li+m+ to \li+outcome+: if all premises have been
satisfied, it draws the horizontal line that builds a new node in the derivation
tree.

\begin{itemize}

  \item \li+premise+ is the composition of \li+tell+, which records the
    derivation for this sub-goal, and \li+return+, which passes the state on to
    the next sub-goal.

  \item \li+prove+ is a computation in the \li+M+ monad (here, \li+MOption+). If
    all the premises have been satisfied, it bundles them as a new node of the
    derivation tree. If a premise failed, then \li+x+ is \li+M.nothing+, and
    \li+prove+ also returns a failed outcome.

  \item \li+axiom+ is short-hand for a rule that requires no premises.

  \item \li+fail+ is for situations where no rule applies: this is a failed outcome.

  \item \li+qed+ is a convenience combinator that pairs the state with the name
    of the rule we want to conclude with; it makes the implementation of
    \li+solve+ (\fref{solver2}) more elegant.

\end{itemize}

\subsection{A solver in the new style}

\fref{solver2} demonstrates an implementation of \li+solve+ in the new style.
Compared to the previous implementation (\fref{solver}):
\begin{itemize}
  \item \li+prove_equality+ makes it explicit which rules are applied, and
    singles out two distinct rule applications in the flexible-rigid case;
  \item the premises of each rule are clearly identified;
  \item axioms and failure conditions are explicit,
  \item the \li+And+ case is easy to review manually, to make sure that no
    premise was forgotten.
\end{itemize}
This is, as mentioned previously, a minimal example that showcases the usage of
the library. In the implementation of Mezzo, switching the core of the
type-checker to this style revealed several bugs where premises were not
properly chained or simply forgotten.

\begin{figure}
  \centering
\begin{ocaml}
let rec prove_equality (state: state) (goal: formula) (v1: var) (v2: var) =
  let open MOption in
  match P.find v1 state, P.find v2 state with
  | Flexible, Flexible
  | Flexible, Rigid ->
      let state = P.union v1 v2 state in
      prove goal begin
        (* Recursive call reduces to the [axiom ... R_Refl] case below. *)
        premise (prove_equality state goal v1 v2) >>=
        qed R_Instantiate
      end
  (* ... *)
  | Rigid, Rigid ->
      if P.same v1 v2 state then
        axiom state goal R_Refl
      else
        fail

let rec solve (state: state) (goal: formula): state outcome =
  match goal with
  | Equals (v1, v2) ->
      prove_equality state goal v1 v2
  | And (g1, g2) ->
      prove goal begin
        premise (solve state g1) >>= fun state ->
        premise (solve state g2) >>=
        qed R_And
      end
\end{ocaml}
  \caption{A solver written using the high-level combinators (client code)}
  \label{fig:solver2}
\end{figure}

\section{Backtracking}
\label{sec:backtracking}

\subsection{Limitations of the option monad}

We now extend our formulas with disjunctions (\fref{choice}). A consequence
is that we now need our base monad \li+M+ to offer a new operation; namely, one
that, among several possible choices, picks the first one that is not a failure.
We thus augment \li+MOption+ with a search combinator (\fref{choice}), which in
turn allows us to implement a high-level \li+choice+ combinator for our
library. The \li+choice+ combinator attempts to prove a \li+goal+ by trying a
function \li+f+ on several arguments of type \li+a+, each of which
has a given \li+outcome+. We extend \li+solve+ with an extra case,
which attempts to prove a disjunction by first trying a
left-elimination (\Rule{Or-L}, \fref{proof-system2}), then a right-elimination
(\Rule{Or-R}).

\begin{figure}
  \centering
  \begin{mathpar}
    \inferrule[Or-L]{
      V \vdash P \dashv V'
    }{
      V \vdash P \vee Q \dashv V'
    }

    \inferrule[Or-R]{
      V \vdash Q \dashv V'
    }{
      V \vdash P \vee Q \dashv V'
    }
  \end{mathpar}
  \caption{New proof rules for disjunction}
  \label{fig:proof-system2}
\end{figure}

\begin{figure}
  \centering
\begin{ocaml}
(* We extend formulas with disjunctions. *)
type formula =
  (* ... *)
  | Or of formula * formula

(* The logic is also extended with two rules. *)
type rule_name =
  (* ... *)
  | R_OrL
  | R_OrR

module MOption = struct
  (* ... *)
  let rec search f = function
    | [] -> None
    | x :: xs ->
        match f x with
        | Some x -> Some x
        | None -> search f xs
end

(* Equipped with [search], we define the [choice] library combinator... *)
let choice (goal: goal) (args: 'a list) (f: 'a -> ('b * rule_name) m): 'b outcome =
  M.search (fun x -> prove goal (f x)) args

(* ...which one uses as follows: *)
let rec solve (state: state) (goal: formula): state outcome =
  match goal with
  (* ... *)
  | Or (g1, g2) ->
      choice goal [ R_OrL, g1; R_OrR, g2 ] (fun (r, g) ->
        premise (solve state g) >>=
        qed r
      )
\end{ocaml}
  \caption{The choice combinator (library and client code)}
  \label{fig:choice}
\end{figure}

The solver can now solve problems of the form $x = z \vee \f y = z$. It fails,
however, to solve problems of the form $(\f y = x \vee \f y = z) \wedge \f y =
z$. The reason is, the option monad is not powerful enough: upon finding a
suitable choice in the disjunction case, it commits to it and drops the other
one. In other words, when hitting the disjunction, \li+MOption+ commits to
$\sigma = \{ \f y \mapsto x \}$, instead of keeping $\sigma = \{ \f y \mapsto z
\}$ as a backup solution. Phrased yet again differently, we need to replace
\li+MOption+ with the non-determinism monad that will implement
\emph{backtracking}.

\subsection{The exploration monad}

Conceptually, we want to change our way of thinking; instead of thinking of
\li+solve+ as a function that returns \emph{a solution}, we now think of it as a
function that returns \emph{several possible solutions}. The state is now a
set of states, each of which represent a path in the search tree of derivation
trees.

The monad of non-determinism is implemented using lists; OCaml is a strict
language, so we write the non-determinism monad (also known as the exploration
or backtracking monad) using lazy lists (\fref{mexplore}).

\begin{figure}
  \centering
\begin{ocaml}
module LL = LazyList
module MExplore
  type 'a m = 'a LL.t
  let return = LL.one
  let ( >>= ) = LL.flattenl (LL.map f x)
  let nothing = LL.nil
  let search f l = LL.bind (LL.of_list l) f
end
\end{ocaml}
  \caption{The exploration monad}
  \label{fig:mexplore}
\end{figure}

The reader can now go back and replace \li+module M = MOption+ with
\li+module M = MExplore+ in \fref{writer}. The rest of the library remains
unchanged; the \li+solve+ function (the client code) is also unchanged; and the
combinators of the library now implement backtracking.

In particular, the earlier example of $(\f y = x \vee \f y = z) \wedge \f y = z$ is now successfully solved by the
library. Thanks to laziness, no extra computations occur; further solutions down
the lazy list are only evaluated if the first ones failed.

\section{Extension: quantifiers and proof trees}
\label{sec:generate-logical}

We mentioned earlier that the derivation we were building tracked the
application of algorithmic rules; that is, we were building a \emph{trace} of
the algorithm. While the trace is useful to extract information for the user,
one may also want to build a proper proof witness in order to certify the
validity of the formula.

In order to make a proof tree relevant and not just provide the substitution as
the proof witness, we introduce quantifiers to the language, and construct proof
trees that apply the proof rules from \fref{logic}, \fref{proof-system2},
\fref{logic-quantifiers}. The nodes of the proof tree are rules; each node is
annotated, if applicable, by its implicit parameters. That is, \Rule{Refl} and
\Rule{ExistsE} are annotated with their implicit $x$ parameter.

\begin{figure}
  \centering
  \begin{mathpar}
    \inferrule[ForallE]{
      P
    }{
      \forall y.\ P
    }
  \end{mathpar}
  \caption{Extra rule for the universal quantifier}
  \label{fig:logic-quantifiers}
\end{figure}

\begin{figure}
  \centering
\begin{ocaml}
(* i) Update of the [MyLogic] module. *)
type formula =
  (* ... *)
  | Exists of string * formula
  | Forall of string * formula

type rule_name =
  | R_And
  | R_Refl of atom
  | R_OrL
  | R_OrR
  | R_ExistsE of atom
  | R_ForallE

(* ii) Update of the [Derivations] module. *)
type derivation =
  goal * rule

and goal =
  L.state * L.formula

and (* ... *)

(* iii) Update of the [Combinators] module. *)
let prove (goal: Logic.formula) (x: ('a * rule_name) m): 'a outcome =
  M.(x >>= fun (premises, (env, rule)) ->
    return (env, ((env, goal), (rule, Premises premises))))

(* iv) Update of the client. *)
let rec solve (state: state) (goal: formula): state outcome =
  (* ... *)
  | Exists (atom, g) ->
      let var, g, state = open_flexible state atom g in
      let var = assert_open var in
      prove goal begin
        premise (solve state g) >>= fun state ->
        qed (R_ExistsE (name var state)) state
      end
\end{ocaml}
  \caption{Dealing with quantifiers}
  \label{fig:quantifiers}
\end{figure}

The updates to the library required to implement quantifiers are minimal; the
bulk of the work is essentially writing substitution and a proper treatment of
binders on the client-side.

\fref{quantifiers} presents in an informal style the series of updates
required.
\begin{enumerate}[i)]
  \item We augment the data type of formulas with quantifiers; we replace the
    type of rules with the rules from the logic. Furthermore, we demand that the
    \Rule{Refl} and \Rule{ExistsE} rules be annotated with their argument.

    Bound variables are globally-unique atoms (strings); open variables are
    equivalence classes of the union-find, as before (not shown here).

  \item We previously did not distinguish between a \li+goal+ and a
    \li+formula+; this was only possible because we assumed all variables were
    initially open, meaning that we could deference an open variable in any
    \li+state+. Now, we open binders and substitute variables, through the
    allocation of new points in the union-find (the \li+state+). Therefore, a
    given \li+formula+ only makes sense when paired with a specific \li+state+.

  \item We update the \li+prove+ combinator to record the \li+state+ upon
    creating a new node in the derivation tree. More precisely, the \li+prove+
    combinator records the \li+state+ after the premises have been satisfied.

  \item Only a slight is needed on the client side to record a proper proof
    witness: in the \li+Exists+ case, the solver prods the union-find state to
    discover the instantiation choice that \emph{has been made} for the
    existentially-quantified variable, and records it in the proof tree.
\end{enumerate}

The sample code in the library comes with a pretty-printer. Here is the output
for a simple formula that combines all features from our formula language.

\begin{verbatim}
prove ∀x. ∀z. ∃y. (y = x \/ y = z) /\ y = z using [forall]
| prove ∀z. ∃y. (y = x \/ y = z) /\ y = z using [forall]
| | prove ∃y. (y = x \/ y = z) /\ y = z using [exists[z]]
| | | prove (z = x \/ z = z) /\ z = z using [/\]
| | | | prove z = x \/ z = z using [\/_r]
| | | | | prove z = z using axiom [refl[z]]
| | | | prove z = z using axiom [refl[z]]
\end{verbatim}

\section{Extending the library; extending the logic; limitations}
\label{sec:extending}

The approach advocated in the present paper works well for sequent-style
calculi; in the context of Mezzo, the logic is extended with the following extra
features:
\begin{itemize}
  \item function symbols, such as, but not limited to: ML arrow types ($\to$),
    type applications ($\mathsf{list}\ \alpha$), constructor applications
    ($\mathsf{Cons}\;\{ \mathsf{head}:\alpha;\ \mathsf{tail}:\mathsf{list}\
    \alpha\}$)
  \item positive and negative positions (also known as ``variance'' in
    type-checking lingo; this applies to function symbols, such as arrows or
    type constructors)
  \item higher-order quantification ($\forall (p: \mathsf{predicate}) \ldots$)
  \item affinity (where some hypothesis may be used at most once)
  \item framing, which bears some similarities with focusing.
\end{itemize}

This in turn requires the client code to keep track of more information, while
also adopting more sophisticated data structures. In particular, the client code
now carries, in addition to a substitution (\emph{a.k.a.} union-find), a
\emph{set} of available hypotheses, which flows left-to-right in the algorithmic
rules. Changing polarities changes the direction of the flow.

For the complete system (Mezzo), there are many more backtracking points. The
client code choses to backtrack on only a subset of them.

A limitation of this library is that it only works as long as every branch of
the exploration terminates; contrary to Kiselyov \emph{et al}.'s
library~\cite{oleg05}, we do not implement fair interleaving. One could
conceivably bound the depth of the search tree, but the exploration of the tree
remains sequential, not concurrent.

If one is willing to give up on modularity, stronger static guarantees can be
attained by making the \li+rule_name+ type more specific; namely, by encoding in
each constructor the number of premises required. The drawback is that the
library now has to be aware of the specific logic; in the current state of
things, the library is completely agnostic with regards to the client code's
particular logical system.

It is unclear how one could memoize the sub-computations; the state of the
client code (the union-find) may not change very much in the simplified logic
presented here; however, for a more evolved logic, it is likely that the client
state evolves monotonically, and makes memoizing difficult, as the result of
sub-calls depends very much on the state.

\section{Source code}

The library is available online at
\url{https://github.com/msprotz/proof-search-monad}. The file \li+example01.ml+
contains the full implementation of the primitive solver described in
\sref{intro}. The file \li+example02.ml+ contains the backtracking solver
written within the proof search monad, as described in \sref{backtracking}. One
can get the non-backtracking version, described in \sref{derivations}, by
replacing \li+MExplore+ with \li+MOption+. Finally, the file \li+example03.ml+
contains the final algorithm described in \sref{generate-logical}. The
representation of binders adopted in the last example is suboptimal; bound
variables are represented using globally-unique atoms. One may want to use
locally nameless, with De Bruijn indices for bound variables (as used in Mezzo).
It allows keeps the boilerplate to a minimum, though.

\section{Related work}

An article titled ``The Proof Monad'' already exists~\cite{kirchner-munoz-10};
in spite of the closely related title, the article is concerned with a slightly
different problem, namely giving an operational semantics to tactic languages
used in theorem provers. In that sense, the article is related to
Mtac~\cite{ziliani-13}, which is also concerned with a proper monad for writing
tactics in Coq.

Hedges~\cite{hedges-14} compares various explorations monads, notably using the
continuation monad, the selection monad~\cite{escardo-2010} and their respective
monad transformers. The main focus of the article seems to be the relationship
between backtracking and game theory.

Hinze~\cite{hinze-00} shows how to use the backtracking monad transformer, i.e.
add backtracking to any existing monad. It would be interesting to determine
whether our library can be re-implemented using a backtracking monad
transformer, rather than the writer transformer applied to the monad of
non-determinism. The (draft) version of the library used in Mezzo also builds
failed derivations (as error messages) that list all attempted proofs, along
with the first premise that failed; doing so would not be possible using
exceptions.

The \li+choice+ operator is related to polarization and
focusing~\cite{liang-miller-07}. For instance, in the problem $\f y = x \vee \f
y = z$, depending on which side of the disjunction the algorithm considers first,
the outcome is going to be different. This is analogous to a synchronous phase
(where the order of the rules matters, and where a particular choice may have
consequences on the rest of the search). Similarly, one may swap premises
chained by the \li+>>=+ operator, as the order doesn't matter. This is analogous
to a asynchronous phase.

\section{Conclusion}

We presented a support library for writing a proof search engine using
backtracking. The library is parameterized by: the type of formulas; the type of
rule applications; the internal state type of the client. This leaves complete
freedom for the client to define their own logic. By merely using the
combinators of the library, the client gets derivations built for free; this allows
a separate verifier to independently check the steps required to prove the
formula. By opting into the library, the client gets to rewrite their code in a
new syntactic style that makes rule application explicits, forbids ``bundled''
applications of multiple rules at the same time and clearly lays out the
premises required to prove a judgement. Since the code resembles the logical
rules, mistakes are easier to spot.

The logic presented in this paper is as simple as it gets. It does, however,
highlight the main concepts. A version of this library is used in the core of
Mezzo's type-checker. The version of the library used in Mezzo also builds
failed derivations; these failed derivations stop at the first failed premise
or, in case of a choice, list all the failed attempts. We have not yet explained
this last feature as a clean combination of monads and operators, but hope to do
so in the near future.

\section*{Acknowledgments}

I wish to thank Gabriel Scherer who helped me sketch the initial version of the
library; François Pottier for motivating me enough that I would want to write
about it, as well as providing the persistent union-find implementation; and
Anonymous Review \#2 for a very high quality review with numerous excellent
suggestions.

\bibliographystyle{plain}
\bibliography{english,local}

\end{document}
