\documentclass{easychair}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{amstext}
\usepackage{amsthm}
\usepackage{hyperref}

\usepackage{tabularx}
\usepackage{listings}
  \def\li{\lstinline}
  \lstset{
    language=caml,
    flexiblecolumns=false,
    showstringspaces=false,
    basicstyle=\ttfamily,
    framesep=5pt,
    numberstyle=\tiny,
    numbersep=5pt,
    escapeinside={(*}{*)},
    morekeywords={above,abstract,adopts,alias,and,as,assert,begin,below,builtin,consumes,data,do,downto,duplicable,dynamic,else,empty,end,exclusive,explain,fact,fail,flex,for,from,fun,give,if,in,let,match,mutable,open,pack,perm,preserving,rec,take,taking,then,to,type,unknown,val,value,while,with,witness},
    deletekeywords={value},
  }
\usepackage{minted}
  \newminted[ocaml]{ocaml}{mathescape,fontsize=\small}
\usepackage{mathpartir}
  % Improvements to Didier's mathpartir package: make all rule names and
  % references use textsc, and also make references to rules done using the \Rule
  % command clickable in a PDF.
  \let\TirName\textsc
  \renewcommand{\RefTirName}[1]{\hypertarget{#1}{\TirName {#1}}}
  \renewcommand{\DefTirName}[1]{\hyperlink{#1}{\TirName {#1}}}
  \let\DefRule\RefTirName
  \let\Rule\DefTirName


\newcommand{\fref}[1]{Figure~\ref{fig:#1}}
\newcommand{\R}{\ensuremath{\mathcal{R}}} % Rigid
\newcommand{\f}[1]{\ensuremath{#1^?}} % Bold
\newcommand{\F}{\ensuremath{\mathcal{F}}} % Flexible
\newcommand{\V}{\ensuremath{\mathcal{V}}} % The prefix

\begin{document}

\title{Functional Pearl: the Proof Search Monad}
\titlerunning{The Proof Search Monad}

\author{Jonathan Protzenko}
\authorrunning{J. Protzenko}
\institute{
  Microsoft Research\\
  \email{protz@microsoft.com}}

\maketitle

\begin{abstract}
  We present the proof search monad, a set of combinators that allows one to
  write a proof search engine in a style that resembles closely the inference
  rules. The user calls functions such as \li+premise+, \li+prove+ or
  \li+choice+; the library then takes care of generating a derivation tree.
  Proof search engines written in this style enjoy: first, a one-to-one
  correspondence between the implementation and the theoretical rules, which
  makes manual inspection easier; second, proof witnesses ``for free'', which
  makes a verified, independent validation approach easier too.
\end{abstract}

\section{A minimal problem}

We consider conjunctions of equalities of the form
$\bigwedge_k x_i = x_j$, that is, conjunctions of
equalities between variables. Some variables are \emph{flexible}, meaning they may be
substituted with other variables. They are typeset as follows: $\f y$.
Rigid variables may not be substituted. They are typeset as follows: $x$. The
problem consists in computing a substitution of \emph{flexible} variables so that
the conjunction evaluates to \li+true+. If no such substitution exists, the
solver outputs nothing.

For instance, one may want to solve: $x = \f y \wedge z = z$.
A solution exists: the solver outputs $\sigma = \{ \f y \mapsto x \}$ as a valid
substitution that solves the input problem. However, if one attempts to solve:
$x = \f y \wedge \f y = z$, the solver fails to find a
proper substitution, and return nothing. Indeed, the first clause demands that
$\f y$ substitutes to $x$, meaning that the second clause becomes $x = z$, which
always evaluates to false ($x$ and $z$ are two distinct rigid variables).

In proof search, rigid variables stem from the right-elimination of universal
quantifiers, or left-elimination of existential quantifiers, which both result
in abstract variables. When left-eliminating a universal quantifier
(respectively right-eliminating an existential quantifier), one must provide an
argument to the type application (resp. an existential witness). If the argument
(resp. the witness) cannot be found on the spot, one typically uses
\emph{flexible variables}, which allow the proof search procedure to
\emph{defer} the choice until a later point in search (where the choice may be
guessed). Flexible variables are thus an \emph{implementation technique}.

In order to simplify the discussion, we skip elimination rules and quantifiers
altogether, and just assume that our input problem contains a combination of
flexible and rigid variables. Furthermore, we assume that any instantiation of a
flexible variable is legal. The only point that matters is that the solver
computes a result which sequenced throughout the proof search.

(The library that we describe here has been used in the implementation of the
Mezzo type-checker. There, the logic (the type system) does have all four
introduction and elimination rules; in the implementation, we used \emph{levels}
to guarantee that only sound instantiation choices are performed. This is,
however, orthogonal to the present discussion; the minimal problem we consider
already conveys all the important points, so we skip quantifiers in the
remainder of the discussion.)

\fref{proof-system} describes a proof search procedure for conjunctions of
equalities. Rules poke at a set of variables $V$ to tell apart rigid variables from
flexible variables. Each rule takes a substitution $\sigma$ as an input, and outputs
an updated substitution $\sigma'$. A variable in $V$ is either a rigid ($x$),
or a flexible ($\f y$).

\Rule{Refl} embodies the reflexivity axiom; \Rule{And}
highlights that the first sub-goal (premise) produces an \emph{output} $V'$
which is then \emph{chained}
from one premise to another; \Rule{Inst} embodies the ``instantiation''
mechanism: in essence, if $\f y$ has not been instantiated so far, one
may instantiate it onto any other variable (rigid or flexible), i.e. add a new
entry for $\f y$ in the substitution. Finally, \Rule{Subst} may apply the
substitution at any time in order to prove the goal.

\begin{figure}
  \centering
  \begin{mathpar}
    \inferrule[Refl]{
      \quad
    }{
      V, \sigma \vdash x = x \dashv \sigma
    }

    \inferrule[Subst]{
      V, \sigma \vdash \sigma P \dashv \sigma'
    }{
      V, \sigma \vdash P \dashv \sigma'
    }

    \inferrule[Inst]{
      x \in V \\ \f y \in V \\ \f y \not\in \sigma \\\\
      V, \{ \f y \mapsto x \} \circ \sigma \vdash  P \dashv \sigma'
    }{
      V \vdash P \dashv \sigma'
    }

    \inferrule[And]{
      V, \sigma \vdash P \dashv \sigma' \\\\
      V, \sigma' \vdash Q \dashv \sigma''
    }{
      V \vdash P \wedge Q \dashv \sigma''
    }
  \end{mathpar}
  \caption{Semi-algorithmic proof rules}
  \label{fig:proof-system}
\end{figure}

Once the proof tree has been laid out, one obtains an output (e.g. $\sigma''$ in
\Rule{And}). Since flexible variables may instantiate onto other flexible
variables, one may need to apply the substitution several times. The reflexive-transitive
closure of $\sigma$, i.e. $\sigma^*$, is thus the desired result of the proof
search.

\begin{figure}
  \centering
  \begin{ocaml}
type formula =                and descr =
| Equals of var * var           | Flexible
| And of formula * formula      | Rigid

and var = P.point             and state = descr P.state
  \end{ocaml}
  \caption{Formulas and state}
  \label{fig:formulas}
\end{figure}

We implement proof search in OCaml (\fref{formulas}). The data type of formulas
is self-explanatory. Variables are implemented as equivalence classes in a
\emph{persistent} union-find data structure, which the module \li+P+ implements.
The $V$ parameter in our rules is embodied by the \li+state+ type; just
like the $V$ parameter is chained from one premise to another (\Rule{And}),
\li+state+ is an input and an output to the solver. Just like the $V$ parameter
in the rules, a \li+state+ of the persistent union-find represents
a set of equations between variables. In a sense, \li+state+ is a specific
implementation of the theoretical $V$ parameter. It represents a
substitution; in other words, this is what we want our solver to compute.

The choice of a persistent union-find is irrelevant. All that matters is that we
pick a data structure that models substitutions, and that is \emph{persistent}.
Had we picked an explicit substitution instead of a union-find, the rest of the
discussion would have been the same.

\fref{solver} implements a solver for our minimal problem; written within the
\li+MOption+ monad, it returns either \li+Some state+ (in case a successful
substitution has been found), or \li+None+ if no solution exists. The solver is
complete.

\begin{figure}
  \centering
  \begin{ocaml}
module MOption = struct
  (* ... defines [return], [nothing] and [>>=] *)
end

let unify state v1 v2 =                         let rec solve state formula =
  match P.find v1 state, P.find v2 state with     match formula with
  | Flexible, Flexible                            | Equals (v1, v2) ->
  | Flexible, Rigid ->                                unify state v1 v2
      return (P.union v1 v2 state)                | And (f1, f2) ->
  | Rigid, Flexible ->                                solve state f1 >>= fun state ->
      return (P.union v2 v1 state)                    solve state f2
  | Rigid, Rigid ->
      if P.same v1 v2 state then
        return state
      else
        nothing
  \end{ocaml}
  \caption{Solver for the simplified problem}
  \label{fig:solver}
\end{figure}

The solver uses \li+MOption.>>=+ to sequence premises in the \li+And+ case. It
doesn't keep track of premises; it just ensures (thanks to \li+>>=+) that if the
first premise evaluates to \li+nothing+, the second premise is not evaluated,
since it is suspended behind a \li+fun+ expression (OCaml is a strict language).

\section{Building derivations}

There are two shortcomings with this solver. First, the \li+unify+ sub-routine
conflates several rules of the logic together. Indeed, the \li+return (P.union ...)+
expression hides a combination of \Rule{Inst} and \Rule{Refl}. Second, we
have no way to replay the proof to verify it independently. One may argue that
in this simplified example, one can just apply the substitution to the original
formula and verify that all the clauses are of the form $x = x$, without the
need for a proof tree. In the general case, however, the proof tree contains the
elimination witnesses for quantifiers; this allows one to independently verify a
proof without relying on inference techniques, such as flexible variables.

\subsection{Defining proof trees}

One way to make the solver better is to make sure each step it performs
corresponds in an obvious manner to the application of an admissible rule. To
that effect, we define the data type of all three rules in our system, which we
apply to the functor of \emph{proof trees} (\fref{proof-trees}).

\begin{figure}
  \centering
\begin{ocaml}
module type LOGIC = sig     module MakeProofTree (L: LOGIC) = struct
  type formula                type derivation = L.formula * rule
  type rule_name              and rule = L.rule_name * premises
end                           and premises = Premises of derivation list
                            end 

module MyLogic = struct
  type formula = ... (* as before *)
  type rule_name = R_And | R_Refl | R_Inst
end
module MyProofTree = MakeProofTree(MyLogic)
\end{ocaml}
  \caption{The functor of proof trees}
  \label{fig:proof-trees}
\end{figure}

A \li+derivation+ tree is a pair of a \li+formula+ (the goal we wish the prove)
and a \li+rule+ (that we apply in order to prove the goal). A \li+rule+ has a name
and \li+premises+; the \li+premises+ type is simply a \li+derivation list+ (the
\li+Premises+ constructor is here to prevent a non-constructive type
abbreviation). When using the library, the client is expected to make sure
that each \li+rule_name+ is paired with the proper
number of premises (0 for \Rule{Refl}, 1 for
\Rule{Inst} and 2 for \Rule{And}); this is not enforced by the type system.

In the (simplified) sketch from \fref{proof-trees}, rule names are just constant
constructors, since the rule parameters (such as $x$ and $\f y$ in \Rule{Inst})
can be recovered from the \li+formula+. In the general case, the various
constructors of \li+rule_name+ do have parameters that record how one specific
rule was instantiated.

\subsection{Proof tree combinators}

We previously used the \li+>>=+ operator from the \li+MOption+ monad in order to
chain premises (\fref{solver}). We now need a new operator, that not only
\emph{binds} the result (i.e. stops evaluating premises after a failure, as
before), but also \emph{records} the premises in sequence, in order to build a
proper derivation. The former is still faithfully implemented by the option
monad; the latter is implemented by the writer monad.

Computations in the writer monad return a result (of type \li+'a+) along with a log of
elements (of type \li+L.a+). The (usual) \li+>>=+ and \li+return+ combinators operate on
the result part of the computation, while the (new) \li+tell+ combinator
operates on the logging part of the computation. This \li+tell+ combinator
appends a new element to the log. Appending elements to the log is done by way of the \li+MONOID+
module type, which essentially demands a value for the empty log, and a function to
append new entries into the log.

In order to get a new \li+>>=+ operator that combines the features of
the option and writer monads, we apply the \li+WriterT+ monad transformer to the
\li+MOption+ monad (\fref{writer}) and obtain \li+MWriter+, a monad whose
computations represent a sequence of derivations (the premises we have proved so far)
along with a result (the \li+state+ that we chain through the premises). These
computations are wrapped in \li+MOption.m+, that is, are wrapped within an
\li+option+ to account for a possible proof failure.

\begin{figure}
  \centering
\begin{ocaml}
module WriterT (M: MONAD) (L: MONOID): sig      module L = struct
  type 'a m = (L.a * 'a) M.m                      type a = MyProofTree.derivation list
  val return: 'a -> 'a m                          let empty = []
  val ( >>= ): 'a m -> ('a -> 'b m) -> 'b m       let append = List.append
                                                end
  val tell: L.a -> unit m
end = ...

module M = MOption
module MWriter = WriterT(M)(L)
\end{ocaml}
  \caption{The writer monad transformer}
  \label{fig:writer}
\end{figure}

A computation within this new monad has type (simplified after functor applications)
\li+(derivation list * state) option+. It represents a given point in the proof;
the solver is focused on a given rule, has reached a certain state, after
proving a certain list of premises.

Once all the premises have been proved, one needs to draw a horizontal line and
reach the conclusion of the proof. That is, take the final state and the list of
premises, and generate a \li+derivation+ that stands for the application of the
entire rule.

Contrary to the first implementation (\fref{solver}), where the working state
and the return value of \li+solve+ both had type \li+state option+, we now
distinguish between an \li+outcome+ (the result of a call to \li+solve+) and a
working state (a computation in the monad).

An outcome is, as we mentioned earlier, the pair of a final \li+state+ along
with a \li+derivation+ that justifies that we reached this state. The pair is
optional since, after all, not all formulas are provable.

The type \li+outcome+ (\fref{combinators}) is parametric: it works for any
state that the client code uses. In other words, our library is generic with
regards to the particular \li+state+ type the client uses.

\begin{figure}
  \centering
\begin{ocaml}
(* This snippet is in the [MWriter(M)(L)] monad. Upon a first reading, think
   [module M = MOption]. *)
type 'a outcome = ('a * derivation) M.m

let premise (outcome: 'a outcome): 'a m =
  M.bind outcome (fun (state, derivation) ->
    tell [ derivation ] >>= fun () ->
    return state
  )

let prove (goal: goal) (rule: rule_name) (x: 'a m): 'a outcome =
  M.(x >>= fun (premises, state) ->
    return (state, (goal, (rule, Premises premises))))

let axiom (state: 'a) (goal: goal) (axiom: rule_name): 'a outcome =
  prove goal axiom (return state)

let fail: 'a outcome =
  M.nothing
\end{ocaml}
  \caption{The high-level combinators for building proof derivations}
  \label{fig:combinators}
\end{figure}

We now have a duality between the \li+outcome+ type (the result of solving a
sub-goal) and the \li+m+ type (a computation within the monad, i.e. a working
state between two premises). Therefore, we introduce two high-level combinators:
\li+premise+ and \li+prove+. The former goes from \li+outcome+ to \li+m+: it
injects a new sub-goal as a premise of the rule we are currently trying to
prove. The latter goes from \li+m+ to \li+outcome+: if all premises have been
satisfied, it draws the horizontal line that builds a new node in the derivation
tree.

\begin{itemize}

  \item \li+premise+ is the composition of \li+tell+, which records the
    derivation for this sub-goal, and \li+return+, which passes the state on to
    the next sub-goal.

  \item \li+prove+ is a computation in the \li+M+ monad (here, \li+MOption+). If
    all the premises have been satisfied, it bundles them as a new node of the
    derivation tree. If a premise failed, then \li+x+ is \li+M.nothing+, and
    \li+prove+ also returns a failed outcome.

  \item \li+axiom+ is short-hand for a rule that requires no premises.

  \item \li+fail+ is for situations where no rule applies: this is a failed outcome.
\end{itemize}

\subsection{A solver in the new style}

\fref{solver2} demonstrates an implementation of \li+solve+ in the new style.
Compared to the previous implementation (\fref{solver}):
\begin{itemize}
  \item \li+prove_equality+ makes it explicit which rules are applied, and
    singles out two distinct rule applications in the flexible-rigid case;
  \item the premises of each rule are clearly identified;
  \item axioms and failure conditions are explicit,
  \item the \li+And+ case is easy to review manually, to make sure that no
    premise was forgotten.
\end{itemize}
This is, as mentioned previously, a minimal example that showcases the usage of
the library. In the implementation of Mezzo, switching the core of the
type-checker to this style revealed several bugs where premises were not
properly chained or simply forgotten.

\begin{figure}
  \centering
\begin{ocaml}
let rec prove_equality (state: state) (goal: formula) (v1: var) (v2: var) =
  let open MOption in
  match P.find v1 state, P.find v2 state with
  | Flexible, Flexible
  | Flexible, Rigid ->
      let state = P.union v1 v2 state in
      prove goal R_Instantiate begin
        premise (prove_equality state goal v1 v2) >>=
        return
      end
  (* ... *)
  | Rigid, Rigid ->
      if P.same v1 v2 state then
        axiom state goal R_Refl
      else
        fail

let rec solve (state: state) (goal: formula): state outcome =
  match goal with
  | Equals (v1, v2) ->
      prove_equality state goal v1 v2
  | And (g1, g2) ->
      prove goal R_And begin
        premise (solve state g1) >>= fun state ->
        premise (solve state g2) >>=
        return
      end
\end{ocaml}
  \caption{A solver written using the high-level combinators}
  \label{fig:solver2}
\end{figure}

\section{Backtracking}

\subsection{Limitations of the option monad}

We now extend our formulas with disjunctions (\fref{choice}). A consequence
is that we now need our base monad \li+M+ to offer a new operation; namely, one
that, among several possible choices, picks the first one that is not a failure.
We thus augment \li+MOption+ with a search combinator (\fref{choice}), which in
turn allows one to implement a high-level \li+choice+ combinator for our
library. The \li+choice+ combinator attempts to prove a \li+goal+ by trying a
function \li+f+ on several arguments \li+a+, each of which
is associated to a given rule. We can add one more branch to the \li+solve+
function, which attempts to prove a disjunction by first trying a
left-elimination (\Rule{Or-L}, \fref{proof-system2}), then a right-elimination
(\Rule{Or-R}).

\begin{figure}
  \centering
  \begin{mathpar}
    \inferrule[Or-L]{
      V \vdash P \dashv V'
    }{
      V \vdash P \vee Q \dashv V'
    }

    \inferrule[Or-R]{
      V \vdash Q \dashv V'
    }{
      V \vdash P \vee Q \dashv V'
    }
  \end{mathpar}
  \caption{New proof rules for disjunction}
  \label{fig:proof-system2}
\end{figure}

\begin{figure}
  \centering
\begin{ocaml}
(* We extend formulas with disjunctions. *)
type formula =
  (* ... *)
  | Or of formula * formula

(* The logic is also extend with two rules. *)
type rule_name =
  (* ... *)
  | R_OrL
  | R_OrR

module MOption = struct
  (* ... *)
  let rec search f = function
    | [] -> None
    | x :: xs ->
        match f x with
        | Some x -> Some x
        | None -> search f xs
end

(* Equipped with [search], we define the high-level [choice] combinator... *)
let choice (goal: goal) (args: (rule_name * 'a) list) (f: 'a -> 'b m): 'b outcome =
  M.search (fun (r, x) -> prove goal r (f x)) args

(* ...which one uses as follows: *)
let rec solve (state: state) (goal: formula): state outcome =
  match goal with
  (* ... *)
  | Or (g1, g2) ->
      choice goal [ R_OrL, g1; R_OrR, g2 ] (fun g ->
        premise (solve state g) >>=
        return
      )
\end{ocaml}
  \caption{The choice combinator}
  \label{fig:choice}
\end{figure}

The solver can now solve problems of the form $x = z \vee
\f y = z$. It fails, however, to solve problems of the form $(\f y = x \vee \f y = z) \wedge \f y = z$. The reason is, the option monad
is not powerful enough: upon finding a suitable choice in the disjunction
case, it commits to it and drops the other one. In other words, when hitting the
disjunction, \li+MOption+ commits to $\sigma = \{ \f y \mapsto x \}$, instead of
keeping $\sigma = \{ \f y \mapsto z \}$ as a backup solution. Phrased yet again
differently, we need to replace \li+MOption+ with the non-determinism monad that
will implement \emph{backtracking}.

\subsection{The exploration monad}

Conceptually, we want to change our way of thinking; instead of thinking of
\li+solve+ as a function that returns \emph{a solution}, we now think of it as a
function that returns \emph{several possible solutions}. The state is now a
set of states, each of which represent a path in the search tree of derivation
trees.

The monad of non-determinism is implemented using lists; OCaml is a strict
language, so we write the non-determinism monad (also known as the exploration
or backtracking monad) using lazy lists (\fref{mexplore}).

\begin{figure}
  \centering
\begin{ocaml}
module LL = LazyList
module MExplore
  type 'a m = 'a LL.t
  let return = LL.one
  let ( >>= ) = LL.flattenl (LL.map f x)
  let nothing = LL.nil
  let search f l = LL.bind (LL.of_list l) f
end
\end{ocaml}
  \caption{The exploration monad}
  \label{fig:mexplore}
\end{figure}

The reader can now go back and replace \li+module M = MOption+ with
\li+module M = MExplore+ in \fref{writer}. The rest of the library remains
unchanged; the \li+solve+ function (the client code) is also unchanged; and the
combinators of the library now implement backtracking.

In particular, the earlier example of $(\f y = x \vee \f y = z) \wedge \f y = z$ is now successfully solved by the
library. Thanks to laziness, no extra computations occur; further solutions down
the lazy list are only evaluated if the first ones failed.

\section{Conclusion}

We presented a support library for writing a proof search engine using backtracking in
any given logic; indeed, the library is parameterized by: the type of formulas; the type of
rule applications; the internal state type of the client. By merely using the
combinators of the library, the client gets derivations built for free; this allows
a separate verifier to independently check the steps required to prove the
formula. By opting into the library, the client gets to rewrite their code in a
new syntactic style that makes rule application explicits, forbids ``bundled''
applications of multiple rules at the same time and clearly lays out the
premises required to prove a judgement. Since the code resembles the logical
rules, mistakes are easier to spot.

The logic presented in this paper is as simple as it gets. It does, however,
highlight the main concepts. A version of this library is used in the core of
Mezzo's type-checker. The version of the library used in Mezzo also builds
failed derivations; these failed derivations stop at the first failed premise
or, in case of a choice, list all the failed attempts. We have not yet explained
this last feature as a clean combination of monads and operators, but hope to do
so in the near future.

\bibliographystyle{abbrvnat}
\bibliography{local}

\end{document}
